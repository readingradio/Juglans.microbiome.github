lines(x,y=dnorm(x,mean=0,sd=0.75),lwd=2,col="goldenrod")#
text(x=0,y=0.57,labels="SD = .75")#
text(x=0,y=0.32,labels="SD = 1")
qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1)
abline(qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1))
abline(a=qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1))
abline(b=qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1))
abline(a=qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1), b=0)
?abline
abline(v=qnorm(p=c(.025,.05,.95,.975), mean=0, sd=1))
x <- rnorm(n=10000, mean=0, sd=1)#
hist(x)
hist(x, freq=FALSE)
mean(x); sd(x)
quantile(x, probs=c(.025,.05,.95,.975))
x <- seq(from=-1,to=3,by=.001)#
plot(x,y=dunif(x,min=-1,max=3),type="n",xlim=c(-1,3),ylim=c(0,.4),ylab="density",#
     main="Uniform probability distribution")
lines(x,y=dunif(x,min=-1,max=3),lwd=2)
lines(x=c(-1,-1),y=c(0,dunif(-1,min=-1,max=3)),lwd=2,col="red")
dunif(x, min=-1, max=3)
lines(x=c(3, 3), y=c(0, dunif(3, min=-1, max=3)), lwd=2, col="red")
text(x=1, y=0.32, labels="f(x) = 1/(max - min)", cex=1.3)
x <- runif(n=100000, min=0, max=1)
x
x <- sort(x)
quantile(x, probs=c(.01,.05,.5,.95,.99))  # True values are simply the quantiles (why?)
x <- runif(n=100000, min=0, max=1)
quantile(x, probs=c(.01,.05,.5,.95,.99))  # True values are simply the quantiles (why?)
x <- sort(x) # sorts the random values#
quantile(x, probs=c(.01,.05,.5,.95,.99))  # True values are simply the quantiles (why?)
round(quantile(x, probs=c(.01,.05,.5,.95,.99)), 4)
1/1000
dbinom(x=c(0,1), size=1, prob=.25)
pr <- dbinom(x=c(0:10), size=10, prob=.25)
.25^x * (1-.25)^(1-1)
dbinom(x=c(0,1), size=1, prob=.25)
.25^1 * (1-.25)^(1-1)
pr <- dbinom(x=c(0:10), size=10, prob=.25) # pr(success) = .25
pr
sum(pr)
par(mfrow=c(2,2))  # This sets the plotting space for 2 rows and 2 columns of figures
plot(x=seq(0,1,1), dbinom(x=seq(0,1,1),size=1,prob=.25), xlab="Number of Successes", ylab="Density",#
     main="Binomial for 1 trial, p=.25", ylim=c(0,.8), col="red", pch=16, cex=1.3)
plot(x=seq(0,10,1), dbinom(x=seq(0,10,1), size=10, prob=.25), xlab="Number of Successes", ylab="Density",#
     main="Binomial for 10 trials, p=.25",ylim=c(0,.3),col="red",pch=16,cex=1.3)
plot(x=seq(0,50,1), dbinom(x=seq(0,50,1),size=50,prob=.25), xlab="Number of Successes", ylab="Density",#
     main="Binomial for 50 trials, p=.25", ylim=c(0,.15), col="red", pch=16, cex=1.3)
plot(x=seq(0,1000,1),d binom(x=seq(0,1000,1), size=1000,prob=.25), xlab="Number of Successes", ylab="Density",#
      main="Binomial for 1000 trials, p=.25", ylim=c(0,.03), xlim=c(100,400), col="red", pch=16, cex=1.3)
plot(x=seq(0,1000,1),d binom(x=seq(0,1000,1), size=1000,prob=.25), xlab="Number of Successes", ylab="Density", main="Binomial for 1000 trials, p=.25", ylim=c(0,.03), xlim=c(100,400), col="red", pch=16, cex=1.3)
plot(x=seq(0,1000,1), dbinom(x=seq(0,1000,1), size=1000,prob=.25), xlab="Number of Successes", ylab="Density", main="Binomial for 1000 trials, p=.25", ylim=c(0,.03), xlim=c(100,400), col="red", pch=16, cex=1.3)
par(mfrow=c(1,1))
x <- rbinom(n=1000, size=100, prob=.25)
quantile(sort(x), probs=c(.5))
quantile(x, probs=c(.5))
par(mfrow=c(2,2))#
hist(rpois(n=10000, lambda=1), main="Poisson, lambda=1", xlab="Counts", breaks=seq(-.5,8.5,1),#
     freq=FALSE, vcol="red", border="black", ylim=c(0, .4))#
lines(0:60, y=dpois(0:60, 1)) # theoretical density#
hist(rpois(n=10000, lambda=2), main="Poisson, lambda=2", xlab="Counts", breaks=seq(-.5,10.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0, .3))#
lines(0:60, y=dpois(0:60, 2))#
hist(rpois(n=10000, lambda=10), main="Poisson, lambda=10", xlab="Counts", breaks=seq(-.5,25.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0,.14))#
lines(0:60, y=dpois(0:60, 10))#
hist(rpois(n=10000, lambda=25), main="Poisson, lambda=25", xlab="Counts", breaks=seq(-.5,48.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0,.085))#
lines(0:60, y=dpois(0:60, 25))#
par(mfrow=c(1, 1))  # always reset the plotting parameters to support 1 figure at a time
par(mfrow=c(2,2))#
hist(rpois(n=10000, lambda=1), main="Poisson, lambda=1", xlab="Counts", breaks=seq(-.5,8.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0,.4))#
lines(0:60, y=dpois(0:60, 1)) # theoretical density#
hist(rpois(n=10000, lambda=2), main="Poisson, lambda=2", xlab="Counts", breaks=seq(-.5,10.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0,.3))#
lines(0:60, y=dpois(0:60, 2))#
hist(rpois(n=10000,lambda=10), main="Poisson, lambda=10", xlab="Counts", breaks=seq(-.5,25.5,1),#
     freq=FALSE, col="red", border="black", ylim=c(0,.14))#
lines(0:60, y=dpois(0:60,10))#
hist(rpois(n=10000,lambda=25), main="Poisson, lambda=25", xlab="Counts", breaks=seq(-.5,48.5,1),#
     freq=FALSE,col="red", border="black", ylim=c(0,.085))#
lines(0:60, y=dpois(0:60,25))#
par(mfrow=c(1, 1))  # always reset the plotting parameters to support 1 figure at a time
?sample  # Note that sampling can be done with or without replacement. Without is default.#
#      Let's do a simple sampling experiment. Imagine that we are selecting from among 3 fruits:#
x <- c("apple", "orange", "mango") # Categorical (character) data#
sample(x, size=3) # Sample at random from x three times, without replacement of sampled fruit.#
                  # Run the command again. Do you get the same ordered outcome?#
sample(x, size=3, replace=TRUE) # Now let's sample at random from x 3 times but w/replacement.#
#      Suppose we had 2 apples in our fruit basket. To randomly sample from the 4 fruits, we#
#      can either define a new vector x with two "apple" elements, or we can use the#
#      prob argument in the sample function.#
sample(x, size=3, replace=TRUE, prob=c(.5,.25,.25)) # The prob vector weights each type of fruit #
                                      # by its relative frequency
library(asbio)  # We'll use some of the functions from asbio #
library(tcltk)
install.packages('asbio')
library(asbio)  # We'll use some of the functions from asbio #
library(tcltk)
samp.dist.snap(parent=expression(rexp(s.size)), stat=mean, s.size = c(1,5,10,50), R = 1000)
samp.dist.snap(rexp(5), stat=mean, s.size = 5, R = 1000)
samp.dist.snap(parent=rexp(5), stat=mean, s.size = 5, R = 1000)
samp.dist.snap(parent=elxpression(rexp(5)), stat=mean, s.size = 5, R = 1000)
samp.dist.snap(parent=e\xpression(rexp(5)), stat=mean, s.size = 5, R = 1000)
samp.dist.snap(parent=expression(rexp(5)), stat=mean, s.size = 5, R = 1000)
randthing<-samp.dist.snap(parent=expression(rexp(5)), stat=mean, s.size = 5, R = 1000)
randthing
samp.dist.snap(rexp(5), stat=mean, s.size = 5, R = 20)
samp.dist.snap(parent=expression(rexp(5)), stat=mean, s.size = 5, R = 20)
samp.dist.snap(parent=expression(rexp(5)), stat=mean, s.size = 5, R = 40)
par(mfrow=c(2,1)) # plotting frame with 2 rows and 1 column#
x <- rnorm(n=10000, mean=50, sd=8)  # Sample from a normal distribution with mean=50 and sd=8#
mean(x); sd(x)#
hist(x, breaks=30, main="Original")
z <- scale(x=x, center=TRUE, scale=TRUE)#
mean(z); sd(z)#
hist(z, breaks=30, main="Standardized") # Shape does NOT change#
par(mfrow=c(1,1))
x <- seq(from=-4,to=4,by=.001)#
plot(x,y=dt(x,df=1),type="n",ylim=c(0,.6),ylab="density",main="Student's t distribution")#
lines(x,y=dt(x,df=1),lwd=2)#
lines(x,y=dt(x,df=5),lwd=2,col="goldenrod")#
lines(x,y=dt(x,df=25),lwd=2,col="green")
legend("topright",col=c("black","goldenrod","green"),lty=1,legend=c("df = 1", "df = 5", "df = 25"))
qt(p=c(.025,.975), df=1) # Critical values, alpha = .025 (or .05 if two-tailed test)#
qt(p=c(.025,.975), df=100) # Critical values with df=100#
qt(p=c(.025,.975), df=1000000) # Critical values with df=1 million. Do these numbers look familiar?
x <- c(4.6,4,3.2,3.5,3.4,4.8,4.1,4,4.9,2.5) # values from sample of 10 subjects in population#
x.bar <- mean(x)#
x.sd <- sd(x)#
t.crit <- qt(p=.975, df=9) # 9 b/c n - 1 d.f. and we have 10 observations#
lower.ci <- x.bar - t.crit*x.sd/sqrt(10) # lower bound of 95% C.I.#
upper.ci <- x.bar + t.crit*x.sd/sqrt(10) # upper bound of 95% C.I.#
c(x.bar, lower.ci, upper.ci)
ci.mu.t(x, conf=.95)
x <- c(25,30,42,7,100)#
z <- scale(x)#
x#
z#
mean(z); sd(z) # check to verify that standardization resulted in mean=0 and sd=1.#
#          b. Compute in R the 95% confidence interval for the mean from the sample#
#             x in this question. Paste code and answer into Word.#
# Long way:#
x.bar <- mean(x)#
x.sd <- sd(x)#
t.crit <- qt(p=.975, df=4) # 4 b/c n - 1 d.f. and we have 5 observations#
lower.ci <- x.bar - t.crit*x.sd/sqrt(5) # lower bound of 95% C.I.#
upper.ci <- x.bar + t.crit*x.sd/sqrt(5) # upper bound of 95% C.I.#
c(x.bar, lower.ci, upper.ci)#
# Short way: ci.mu.t() function in asbio#
# library(asbio)#
ci.mu.t(x, conf=.95) # Do the results match?
x <- c(25,30,42,7,100)#
z <- scale(x)#
x#
z#
mean(z); sd(z)
?scale
x <- c(25,30,42,7,100)#
z <- scale(x, center=TRUE)#
x#
z#
mean(z); sd(z)
x.bar <- mean(x)#
x.sd <- sd(x)#
t.crit <- qt(p=.975, df=4) # 4 b/c n - 1 d.f. and we have 5 observations#
lower.ci <- x.bar - t.crit*x.sd/sqrt(5) # lower bound of 95% C.I.#
upper.ci <- x.bar + t.crit*x.sd/sqrt(5) # upper bound of 95% C.I.#
c(x.bar, lower.ci, upper.ci)
ci.mu.t(x, conf=.95) # Do the results match?
x <- c(4.6,4,3.2,3.5,3.4,4.8,4.1,4,4.9,2.5) # values from sample of 10 subjects in population
lci.sigma <- (length(x)-1)*(x.sd^2)/qchisq(p=.975, df=9)#
uci.sigma <- (length(x)-1)*(x.sd^2)/qchisq(p=.025, df=9)#
c(x.sd^2, lci.sigma, uci.sigma)
x.bar <- mean(x)#
x.sd <- sd(x)
lci.sigma <- (length(x)-1)*(x.sd^2)/qchisq(p=.975, df=9)#
uci.sigma <- (length(x)-1)*(x.sd^2)/qchisq(p=.025, df=9)#
c(x.sd^2, lci.sigma, uci.sigma)
ci.sigma(x, conf=.95)#
#       A quick look at the Chi-square distribution with 1 d.f.#
q <- seq(.01,5,.01)#
plot(x=q,y=dchisq(q, df=1), type="l") # The type arguments specifies a line (points is default)
library(asbio)
?Venn
Venn(.1,.2,.05)
?Venn
Venn(.1,.2,.05, labA='small', labB='big')
library(ape)
clustal()
install.packages('ape')
n <- 3	# number of rows#
p <- 2	# number of columns#
#
# The matrix() function enables creation of a matrix:#
A <- matrix((c(1,2,3,4,5,6)),nrow=n,ncol=p,byrow=TRUE)  # A is a 3 x 2 matrix#
A#
c <- matrix((c(10,20,30)),nrow=3,ncol=1,byrow=TRUE)	    # c is a 3 x 1 column vector#
c#
r <- t(c)			# the transpose of c, t(c), is a 1 x 3 row vector#
r#
##
# diag() creates a square matrix with ones (or other values) on diagonal#
I <- diag(x=1,nrow=3,ncol=3) # 3x3 Identity matrix has ones on diagonal#
I#
##
#  Matrix
B <- matrix((c(5,6,7,8,9,10)),nrow=n, ncol=p,byrow=TRUE)  # B is a 3 x 2 matrix
A; B  # Let's look at matrix A and matrix B
C <- A+B  # corresponding elements of A and B are added together#
C
s <- 2#
s*C
r/10; c/10#
(r/10)%*%(c/10)  # the %*% around the * operator stipulates #
#                  element-by-element multiplication
r
c
I; c#
I%*%c # 3x3 * 3x1 = 3x1 vector for solution (3 inner products)
c%*%I  # Error! 3x1 * 3x3 is not conformable; can't multiply
I; A#
I%*%A
I[2,2] <- 2		# change value of element [2,2] in I; note square brackets#
I; A#
A%*%I     # Get error message: non-conformable arguments (b/c [3x2] x [3x3] not possible)#
I%*%A
crossprod(I,A) # try crossprod(A, I), where A*I is not conformable#
##
#  Inverse of a matrix#
A <- matrix(c(3,-6,2,-5),2,2,byrow=TRUE)#
A#
solve(A)		# solves for the inverse of A (elements are multiples)#
            # check - does the inverse multiplied by the original yield an identity matrix?#
solve(A) %*% A
install.packages('lawn')
library("lawn")#
lawn_bbox_polygon(c(-122.2047, 47.5204, -122.1065, 47.6139)) %>% view
install.packages('leaflet')
library('leaflet')
lawn_bbox_polygon(c(-122.2047, 47.5204, -122.1065, 47.6139)) %>% view
lawn_bbox_polygon(c(46.591169, -118.535378, 45.741266, -116.686558)) %>% view
lawn_bbox_polygon(c(-118.535378, 46.591169, -116.686558, 45.741266)) %>% view
lawn_bbox_polygon(c(-119, 46.591169, -116.686558, 45.741266)) %>% view
lawn_bbox_polygon(c(-118.535378, 47, -116.686558, 45.741266)) %>% view
lawn_bbox_polygon(c(-119, 47, -116.686558, 45.741266)) %>% view
ncdc_stations(extent =c(-119, 47, -116.686558, 45.741266))
library('rnoaa')
ncdc_stations(extent =c(-119, 47, -116.686558, 45.741266))
?token
?rnoaa
ncdc_stations(extent =c(-119, 47, -116.686558, 45.741266))
?ncdc_stations
ncdc_stations(extent =c(-119, 47, -116.686558, 45.741266), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ')
ncdc_stations(extent = c(47.5204, -122.2047, 47.6139, -122.1065), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ')
ncdc_stations(extent = c(45.741266, -119, 45.741266, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ')
ncdc_stations(extent = c(45.741266, -119, 47, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ')47
ncdc_stations(extent = c(45.741266, -119, 47, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ')
homr(state = 'WA')
stati <- data(ncdc_stations(extent = c(45.741266, -119, 47, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ'), limit=100)
stati <- data(ncdc_stations(extent = c(45.741266, -119, 47, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ', limit=100))
stati <- ncdc_stations(extent = c(45.741266, -119, 47, -116.686558), token='wTFkCIjQSaRynGTPpQQGGjZqnTwZlIxJ', limit=100)
stati
stati$id
stati$data$id
?ncdc
get_GSOD()
library(GSODR)
install.packages('GSODR')
install.packages('gsod')
install.packages("gsod", repos="http://R-Forge.R-project.org")
library(gsod)
help(gsod)
data(stations)
stations
library(ggplot)
library(ggplot2)
library(tidyr)#
library(vegan)#
#
#First I import the whole OTU table I recieved from Mothur. Note at this point taxonomy is not included, it is just raw OTU counts (columns) by sample or group (rows). Below I indicate that the row.names are in column 2 of the imported file. #
bigfile.sample<-read.table("/Users/will1809/OneDrive - purdue.edu/TCD microbiome spring 2017/Results.sep.2019/Caulo.ITS/Spr2017OTU.Jan2018.opti_mcc.branch.shared",header=TRUE,sep="\t",fill=TRUE,strip.white=TRUE, row.names=2)#
#
rownames(bigfile.sample) <- rownames(bigfile.sample) %>% sub('s_S.+', '', ., perl=T)#
#Next I import the metadata for the particular habitat of interest. In this case I am working with drill shavings. I will use this metadata to subset the larger OTU file above. #
source('/Users/will1809/OneDrive - purdue.edu/TCD microbiome spring 2017/Results.sep.2019/Caulo.ITS/baxter.sept2019.R')#
ds.met<- get_metadata()#
#Next I import the taxonomy file. This contains the taxonomy assignments for all OTUs in the study and not just the ones for the particuluar habitat of interest. This will get subset as well. #
taxonomy<-read.table("/Users/will1809/OneDrive - purdue.edu/TCD microbiome spring 2017/Results.sep.2019/Caulo.ITS/jnits.trim.contigs.good.unique.precluster.pick.pick.opti_mcc.0.02.cons.taxonomy",header=TRUE,sep="\t",fill=TRUE,strip.white=TRUE,row.names=1)#
ds.names<-ds.met$Group[ds.met$Type=='BranchBark'] %>% sub('s$', '', ., perl=T)#
#
# added this to deal with sample name issue#
# its confusing but it works#
ds.met2 <- ds.met[ds.met$Type=='BranchBark',]#
#
cbind(ds.met2$Group, ds.names)#
#
ds.met2$sample.name.2 <- ds.names#
#
ds.met2[,c('sample.name.2','Group')]#
#Here I use the subset function to pull out just the samples belonging to drill shavings. #
ds<-subset(bigfile.sample, rownames(bigfile.sample) %in% ds.names)#
dim(ds)#
dspure<- ds[,colSums(ds)>0]#
#Here I am further subsetting the data. I am removing some MOTHUR metadata that is useless.  #
dim(dspure)#
#
dspure[1:4,1:4]#
dspure[1:4,7829:7831]#
dspureotu<-dspure[,3:7831]#
#
dim(dspureotu)#
#Below I am reformatting the OTU table so that I can begin to filter and merge the taxonomy information. #
transdspure<-as.data.frame(t(dspureotu))#
#The below function is asking specifically for the OTU IDs. These are the row names. I will use these to subset the taxonomy file. #
transdspurelabs<-labels(transdspure)#
taxds<-subset(taxonomy, rownames(taxonomy) %in% transdspurelabs[[1]])#
taxdspure<-(taxds[,2])#
#Below I am using the separate function from tidyr to split the taxonomy strings into columns by semi-colon so that I can rename the OTUs to give them more meaning for downstream analyses.#
taxonomylabs<-c("kingdom","phylum","class","order","family","genus","species")#
otutabtaxds<-data.frame(taxonomy=taxdspure,transdspure)#
otutabtaxdssep<-separate(otutabtaxds,into=taxonomylabs,col=taxonomy,sep=";")#
head(otutabtaxdssep)#
#Here I am renaming the OTUs using the make.names function. This will make the OTU name something more informative. I am using genus to do this. #
rownames(otutabtaxdssep)<-make.names(otutabtaxdssep$genus,unique=TRUE)#
rownames(otutabtaxdssep)#
head(otutabtaxdssep)#
#
dim(otutabtaxdssep)#
otutabtaxds<-otutabtaxdssep[,8:54] ### missing a sample#
renamotutabtaxds<-as.data.frame(t(otutabtaxds))#
#Rarefaction#
sort(rowSums(renamotutabtaxds[,1:7829]))#
#Here we are rarefying the data using the rrarefy function from vegan. I use the sort function above to determine the lowest number of sequences in a sample. #
## stopped here 7:33 pm July 25. 2019#
#
rareotuds<-as.data.frame(rrarefy(renamotutabtaxds, sample=3500))#
rareotuds<-as.data.frame(subset(rareotuds,rowSums(rareotuds)>3499))#
samples<-row.names(rareotuds)#
# Lost 1 sample#
#Relabundance calculation#
#relabundds <- rareotuds / 38000#
#
dim(rareotuds)#
rareotutabtaxds<-as.data.frame(rareotuds, total=rowSums(rareotuds[,1:7829]))#
rareotutabtaxds#
#
relabundds<-decostand(rareotutabtaxds, method="total")
pairs(relabundds)
pairs(relabundds[1:10,1:10])
relabundds[1:10,1:10]
pairs(relabundds[,1:10])
pairs(relabundds[,1:10], col=as.numeric(row.names(relabundds)))
row.names(relabundds)
as.numeric(row.names(relabundds))
pairs(relabundds[,1:10], col=as.numeric(as.vector(row.names(relabundds)))
pairs(relabundds[,1:10], col=as.numeric(as.vector(row.names(relabundds))))
pairs(relabundds[,1:10], col=as.numeric(row.names(relabundds[,1:10])))
pairs(relabundds[,1:10], col=as.numeric(row.names(relabundds)[,1:10]))
pairs(relabundds[,1:10], col=as.numeric(row.names(relabundds)))
iris<-cbind(row.names(relabundds),relabundds[,1:10])
iris
pairs(iris[,2:11], col=as.numeric(iris[,1]))
iris.dist<-vegdist(relabundds, method="euclid")
ds
ds.met
adonis(iris.dist ~ ds.met)
dim(iris.dist)
iris.dist<-vegdist(relabundds, method="euclid")
dim(iris.dist)
iris.dist
dims(iris.dist)
dim(iris.dist)
str(iris.dist)
ds.met
adonis(iris.dist ~ ds.met$Clone)
adonis(t(iris.dist) ~ ds.met$Clone)
hclust(iris.dist)
hplot(clust(iris.dist))
plot(hclust(iris.dist))
adonis(relabundds ~ ds.met$Clone)
dim(relabundds)
dim(ds.met)
ds.met2
dim(ds.met2)
ds.met2[,c('sample.name.2','Group')]
rownames(bigfile.sample) %in% ds.names
adonis(relabundds ~ ds.met2$Clone)
adonis(relabundds ~ ds.met2$Clone[-1])
ds.met2$sample.name2
ds.met2$sample.name.2
setideff(ds.met2$sample.name.2, row.names(relabundds))
setdiff(ds.met2$sample.name.2, row.names(relabundds))
relabundds <- relabunnds[-which(row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds))),]
relabundds <- relabundds[-which(row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds))),]
adonis(relabundds ~ ds.met2$Clone[-1])
adonis(relabundds ~ ds.met2$Clone)
dim(relabundds)
dim(ds.met2)
which(row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds)))
relabundds<-decostand(rareotutabtaxds, method="total")
setdiff(ds.met2$sample.name.2, row.names(relabundds))
which(row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds)))
row.names(relabundds)
ds.met2$sample.name.2
row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds)))
which(row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds)))
row.names(relabundds) == setdiff(ds.met2$sample.name.2, row.names(relabundds))
row.names(relabundds) %in% setdiff(ds.met2$sample.name.2, row.names(relabundds))
setdiff(ds.met2$sample.name.2, row.names(relabundds))
missing<-setdiff(ds.met2$sample.name.2, row.names(relabundds))
which(row.names(relabundds) == missing)
row.names(relabundds)
ds.met3 <- ds.met2[-which(ds.met2$sample.name.2 == missing),]
adonis(relabundds ~ ds.met3$Clone)
adonis(relabundds ~ ds.met3$Group)
ds.met3$Group
adonis(relabundds ~ ds.met3$State)
plot(hclust(relabundds))
hclust(relabundds)
relabundds
iris.nmds <- metaMDS(relabundds)
mds.pts <- iris.nmds$points
iris.xy <- scores(mds.pts, display="sites")
plot(mds.pts)
points(iris.xy, col=as.numeric(ds.met3))
points(iris.xy, col=as.numeric(ds.met3$State))
iris.xy
points(iris.xy, col=as.numeric(ds.met3$State))
ds.met3$State
plot(mds.pts, col=as.numeric(ds.met3$State))
as.numeric(ds.met3$State)
ds.met3$State
as.numeric(ds.met3$State)
plot(mds.pts, col=as.numeric(as.factor(ds.met3$State)))
update
install.packages('knitr')
install.packages('rmarkdown')
readline()
words <- readline()
words
subject <- readline()
verb <- readline()
object <- readling()
object <- readline()
paste(subject, verb, object)
# The purpose of this script is to provide tools to explore OTU relationships and abundance of individual taxa in the dataset#
#
library(tidyverse)#
library(phyloseq)#
library(vegan)#
#
# This function queries a subset of the merged bacterial/fungal dataset by a chosen#
# taxonomic level (taxlevel) and the name of the taxon of interest (taxstring).#
# It also takes a phyloseq object (pseq).#
#
custom.otu.tax.tbl <- function(pseq, taxlevel, taxstring) {#
#
  onames <- tax_table(pseq)[,taxlevel] %in% taxstring#
#
  rs <- rownames(tax_table(pseq))[onames]#
#
  if (length(rs) < 1) {#
    return(NULL)#
  } else {#
    mtable <- otu_table(pseq)[onames] %>% cbind (tax_table(pseq)[onames], .) %>% t()#
    return(mtable)#
  }#
}#
#
# This function queries the network analysis results for a specified p and r#
# cutoff for which a correlation table was generated and gives the taxonomic#
# identity of OTUs with significant spearman correlations to G. morbida.#
#
gm.correlations <- function(pseq, pcut, rcut) {#
  correlation.network <- read.csv(paste("Net.analysis/CorrNetworks.WA/cyto.shavings.merged.p.", pcut, ".r.", rcut,".txt", sep = ''), sep='\t')#
  head(correlation.network)#
  v2 <- correlation.network[correlation.network$Var1 == "Otu0115",c('Var2','r','p')]#
  v1 <- correlation.network[correlation.network$Var2 == "Otu0115",c('Var1','r','p')]#
  return(rbind(tax_table(pseq)[as.character(v2$Var2)] %>% cbind (v2[,2:3]), tax_table(pseq)[as.character(v1$Var1)] %>% cbind (v1[,2:3])))#
}#
#
load("R_Environments/Jnigra.microbiome.merged.WilliamsOnufrak.RData")
load("R_Environments/Jnigra.microbiome.merged.WilliamsOnufrak.RData")
custom.otu.tax.tbl(soils.merge, 'Genus', 'g__Fusarium')[,1:10]
custom.otu.tax.tbl(shavings.merge, 'Genus', 'g__Fusarium')
custom.otu.tax.tbl(soils.merge, 'Genus', 'g__Fusarium')
custom.otu.tax.tbl(soils.merge, 'Genus', 'g__Neocosmospora')
custom.otu.tax.tbl(shavings.merge, 'Order', 'o__Ophiostomatales')
custom.otu.tax.tbl(soils.merge, 'Family', 'f__Xylariaceae')
